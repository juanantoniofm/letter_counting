{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Counter - Contador de letras\n",
    "\n",
    "\n",
    "Un pequeño notebook para contar la frecuencia de las letras en el castellano (o en cualquier idioma, siempre que le pases la lista de letras en un CSV).\n",
    "\n",
    "Esto que estas leyendo, es un Jupyter notebook. Puedes utilizarlo como documeto, o como herramienta ejecutable (y que permite modificaciones de forma interactiva). Para saber mas sobre como ejecutarlo, mira la documentacion en [jupyter.org](https://jupyter.org/) y revisa el Makefile.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Internal Assets\n",
    "\n",
    "You can ignore this part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration - Configuracion\n",
    "\n",
    "If you want to change the source of the data, do it here.\n",
    "\n",
    "The format is csv, with one column, with heading (1st row is ignored).\n",
    "\n",
    "---\n",
    "\n",
    "Si necesitas cambiar la fuente de datos, hazlo aqui.\n",
    "\n",
    "El formato es CSV, con una columna, con cabecera (la primera fila se ignora).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/ListaTodasPalabras.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Counting characters\n",
    "\n",
    "Using a clasic method, and removing accents.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Usando un metodo clasico, y eliminando acentos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/ListaTodasPalabras.csv\"\n",
    "# Initialise some variables\n",
    "d = defaultdict(lambda:0)\n",
    "total = 0\n",
    "palabras = []\n",
    "\n",
    "with open(filename) as fh:\n",
    "    # count the total words and the letters\n",
    "    for word in fh.readlines():\n",
    "        if word == \"PALABRAS\\n\":\n",
    "            continue # Ignore the header name\n",
    "        total += 1\n",
    "        palabras.append(word.strip())\n",
    "        noacc = unidecode.unidecode(word)\n",
    "        for letter in noacc.strip():\n",
    "            d[letter] += 1\n",
    "\n",
    "\n",
    "print(\"Letter frequency from least to most\")\n",
    "s = {k: v for k, v in sorted(d.items(), key=lambda item: item[1])}\n",
    "\n",
    "\n",
    "for item,val in s.items():\n",
    "    print(f\"{item} : {val}\")\n",
    "\n",
    "print(\"Total words counted\")\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise some variables\n",
    "d = defaultdict(lambda:0)\n",
    "total = 0\n",
    "palabras = []\n",
    "\n",
    "with open(filename) as fh:\n",
    "    # count the total words and the letters\n",
    "    for word in fh.readlines():\n",
    "        if word == \"PALABRAS\\n\":\n",
    "            continue # Ignore the header name\n",
    "        total += 1\n",
    "        palabras.append(word.strip())\n",
    "        noacc = unidecode.unidecode(word)\n",
    "        for letter in noacc.strip():\n",
    "            d[letter] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Letter frequency from least to most\")\n",
    "s = {k: v for k, v in sorted(d.items(), key=lambda item: item[1])}\n",
    "\n",
    "\n",
    "for item,val in s.items():\n",
    "    print(f\"{item} : {val}\")\n",
    "\n",
    "print(\"Total words counted\")\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain list of usable words from 5 to 6 letters\n",
    "\n",
    "Using pandas and matplotlib.\n",
    "\n",
    "--- \n",
    "\n",
    "Utilizando pandas y matplotlib.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import pandas as pd\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Obtain the list of words from the original database\n",
    "## SLOW Run carefully.\n",
    "\n",
    "wordlist = r'../data/Anexo I - palabras 3-9 letras.xls'\n",
    "\n",
    "#load the sheets for 5 and 6 letters words as Pandas DataFrames\n",
    "words5letters = pd.read_excel (wordlist, sheet_name=\"5\")\n",
    "words6letters = pd.read_excel (wordlist, sheet_name=\"6\")\n",
    "\n",
    "# Extract only the words and the lexyc frequency of words\n",
    "w5l = pd.DataFrame(words5letters ,columns=[\"PALABRA\",\"FRECUENC\"])\n",
    "w6l = pd.DataFrame(words6letters , columns=[\"PALABRA\", \"FRECUENC\"])\n",
    "w6l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the letters into the frequency database \n",
    "\n",
    "To build the statistics about how frequent each letter is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PALABRA</th>\n",
       "      <th>FRECUENC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acá</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adó</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afé</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>ultramicroscopio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>ventriculografía</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>vertiginosamente</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>vicealmirantazgo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>vituperiosamente</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95383 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PALABRA FRECUENC\n",
       "0                 aba        0\n",
       "1                 aca        0\n",
       "2                 acá       46\n",
       "3                 adó        0\n",
       "4                 afé        0\n",
       "..                ...      ...\n",
       "459  ultramicroscopio        0\n",
       "460  ventriculografía        0\n",
       "461  vertiginosamente        2\n",
       "462  vicealmirantazgo        0\n",
       "463  vituperiosamente        0\n",
       "\n",
       "[95383 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Obtain the full database\n",
    "## SLOW Run carefully.\n",
    "\n",
    "wordlist_fileSHORT = r'../data/Anexo I - palabras 3-9 letras.xls'\n",
    "wordlist_fileLONG = r'../data/Anexo II - palabras 10-16 letras.xls'\n",
    "\n",
    "#load the sheets for 5 and 6 letters words as Pandas DataFrames\n",
    "all_words = pd.DataFrame(columns=[\"PALABRA\",\"FRECUENC\"])\n",
    "\n",
    "\n",
    "for i in range(3,10): # range from 3 to 9, inclusive\n",
    "    # wordlist_fileSHORT\n",
    "    sheety = pd.read_excel (wordlist_fileSHORT, sheet_name=f\"{i}\")\n",
    "    all_words = all_words.append( pd.DataFrame(sheety ,columns=[\"PALABRA\",\"FRECUENC\"]) )\n",
    "for i in range(10,17): # range from 10 to 16, inclusive\n",
    "    # wordlist_fileLONG\n",
    "    sheety = pd.read_excel (wordlist_fileLONG, sheet_name=f\"{i}\")\n",
    "    all_words = all_words.append(pd.DataFrame(sheety ,columns=[\"PALABRA\",\"FRECUENC\"]) )\n",
    "\n",
    "\n",
    "all_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clear Up the statistics\n",
    "\n",
    "## GLOBAL Variables\n",
    "# total of words counted\n",
    "word_sum = 0\n",
    "# Freq of each letter\n",
    "letter_frequency = defaultdict(lambda:0)\n",
    "# Distinguish accent (True = i and í are 2 different letters; False = they are 2 letter i's)\n",
    "accent_dif = False # False to ignore, as we won't be using them either for the exercises.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the word into the stats D\n",
    "\n",
    "def is_vowel(letter):\n",
    "    \"\"\" returt if it's a vowel \"\"\"\n",
    "    return unidecode.unidecode(letter) in \"aeiou\"\n",
    "\n",
    "def no_accent(letter):\n",
    "    \"\"\" turn a letter into the no accent equivalent\"\"\"\n",
    "    return unidecode.unidecode(letter) \n",
    "\n",
    "assert is_vowel(\"a\") == True\n",
    "assert is_vowel(\"á\") == True\n",
    "assert is_vowel(\"v\") == False\n",
    "\n",
    "\n",
    "assert no_accent(\"a\") == \"a\"\n",
    "assert no_accent(\"á\") == \"a\"\n",
    "assert no_accent(\"v\") == \"v\"\n",
    "    \n",
    "def count_word(word, letter_frequency = letter_frequency, accent_dif = accent_dif):\n",
    "    global word_sum\n",
    "    # don't count not numbers\n",
    "    if type(word) == type(0.1):\n",
    "        return None\n",
    "    # Count the word to the total of words\n",
    "    word_sum += 1\n",
    "    # We might need to exclude accents, but not the ñ\n",
    "    for letter in word:\n",
    "        if not accent_dif: # we must NOT distinguish accents\n",
    "            if is_vowel(letter):\n",
    "                letter_frequency[no_accent(letter)] += 1\n",
    "            else:\n",
    "                letter_frequency[letter] += 1\n",
    "        else:\n",
    "            letter_frequency[letter] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'palabras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-585a8477c40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### DEBUG Error checking which words are missing on the new data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpalabras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_not_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalabras\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpalabras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'palabras' is not defined"
     ]
    }
   ],
   "source": [
    "### DEBUG Error checking which words are missing on the new data set\n",
    "\n",
    "len(palabras)\n",
    "\n",
    "def is_not_in(word, palabras=palabras):\n",
    "    if word in palabras:\n",
    "        return None\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "    \n",
    "assert is_not_in(\"aba\") == None\n",
    "assert is_not_in(\"somethingrandom\") == \"somethingrandom\"\n",
    "\n",
    "palabras[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG : Running it in one word\n",
    "\n",
    "p = all_words[3].PALABRA[15]\n",
    "f = all_words[3].FRECUENC[15]\n",
    "\n",
    "print(p)\n",
    "print(f)\n",
    "\n",
    "print(\"Stadisticas antes\", word_sum )\n",
    "print(\"Stadisticas antes\", letter_frequency )\n",
    "count_word(p)\n",
    "print(\"Stadisticas despues\", word_sum )\n",
    "print(\"Stadisticas despues\", letter_frequency )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0380d165a006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mbuild_letter_freq_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mletter_frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0380d165a006>\u001b[0m in \u001b[0;36mbuild_letter_freq_table\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#for key, df_words in all_words.items():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#    ## Do what you do to each data frame of words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPALABRA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# make each letter into the stats dir.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_words' is not defined"
     ]
    }
   ],
   "source": [
    "# Running it on all the words\n",
    "## Building the Freq Table. Run Once.\n",
    "\n",
    "palabras_not_in = []\n",
    "\n",
    "def build_letter_freq_table():\n",
    "    \"\"\"\n",
    "    Build the table with the total stats of letter frequency\n",
    "    \"\"\"\n",
    "    #for key, df_words in all_words.items():\n",
    "    #    ## Do what you do to each data frame of words\n",
    "    for word in df_words.PALABRA:\n",
    "        # make each letter into the stats dir.\n",
    "        try:\n",
    "            count_word(word)\n",
    "            #if is_not_in(word):\n",
    "            #    palabras_not_in.append(word)\n",
    "        except TypeError as e:\n",
    "            print(e)\n",
    "            print(word)\n",
    "            print(type(word))\n",
    "            print(\"WTF\")\n",
    "    return None\n",
    "\n",
    "build_letter_freq_table()\n",
    "letter_frequency\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(palabras))\n",
    "print(len(palabras_not_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_not_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = palabras # tendria que ser un data frame.\n",
    "df2 = \n",
    "merged = df1.merge(df2, indicator=True, how='outer')\n",
    "merged[merged['_merge'] == 'right_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"letter_frequency\",letter_frequency)\n",
    "print(\"word_sum\",word_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tenemos la tabla de frec. Necesitamos phi. Hay que calcular, el phi de una palabla.\n",
    "# para el phi, necesitamos, el % de frequencias\n",
    "\n",
    "#suma todas las frec\n",
    "tot_letters = 0\n",
    "for k,v in letter_freqency.items():\n",
    "    tot_letters += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# splitting the words into lists of letters\n",
    "splits = df.apply(lambda x: [y for y in x[0].strip()], axis='columns')\n",
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TXT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP Do not read forward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats of strokes per letter.\n",
    "rasgos = {\n",
    "        \"a\": 3,\n",
    "        \"b\": 4,\n",
    "        \"c\": 2,\n",
    "        \"d\": 3,\n",
    "        \"e\": 3,\n",
    "        \"f\": 4,\n",
    "        \"g\": 4,\n",
    "        \"h\": 4,\n",
    "        \"i\": 3,\n",
    "        \"j\": 3,\n",
    "        \"k\": 5,\n",
    "        \"l\": 2,\n",
    "        \"m\": 6,\n",
    "        \"n\": 4,\n",
    "        \"o\": 3,\n",
    "        \"p\": 4,\n",
    "        \"q\": 3,\n",
    "        \"r\": 3,\n",
    "        \"s\": 3,\n",
    "        \"t\": 4,\n",
    "        \"u\": 4,\n",
    "        \"v\": 4,\n",
    "        \"w\": 6,\n",
    "        \"x\": 4,\n",
    "        \"y\": 5,\n",
    "        \"z\": 5\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying to calculate Phi\n",
    "## Sum of all the % Frequency of each letter in the word\n",
    "\n",
    "def get_phi(letter):\n",
    "    return 1\n",
    "\n",
    "def calc_phi(word=None):\n",
    "    \"\"\" Calculate the phi value of a word.\n",
    "    Phi is the sum of the frequencies of the each letter in a word.\n",
    "    \"\"\"\n",
    "    if word is None:\n",
    "        return 0\n",
    "    phi = 0\n",
    "    for letter in word:\n",
    "        phi += get_phi(letter)\n",
    "    return phi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_phi(\"aa\"), 199)\n",
    "print(calc_phi(\"\"),0)\n",
    "print(calc_phi(),0)\n",
    "print(calc_phi(\"abadia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying to calculate Stroke sum RHO\n",
    "## Sum of all the strokes of each letter in a word\n",
    "\n",
    "def get_rho(letter):\n",
    "    return rasgos[letter]\n",
    "\n",
    "def calc_rho(word=None):\n",
    "    \"\"\" Calculate the Rho value of a word.\n",
    "    Rho is the sum of the strokes of the each letter in a word.\n",
    "    \"\"\"\n",
    "    if word is None:\n",
    "        return 0\n",
    "    rho = 0\n",
    "    for letter in word:\n",
    "        rho += get_rho(letter)\n",
    "    return rho\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_rho(\"aa\"), 6)\n",
    "print(calc_rho(\"\"),0)\n",
    "print(calc_rho(),0)\n",
    "print(calc_rho(\"peluca\"),18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
