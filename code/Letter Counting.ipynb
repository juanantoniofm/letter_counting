{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Counter - Contador de letras\n",
    "\n",
    "\n",
    "Un pequeño notebook para contar la frecuencia de las letras en el castellano (o en cualquier idioma, siempre que le pases la lista de letras en un CSV).\n",
    "\n",
    "Esto que estas leyendo, es un Jupyter notebook. Puedes utilizarlo como documeto, o como herramienta ejecutable (y que permite modificaciones de forma interactiva). Para saber mas sobre como ejecutarlo, mira la documentacion en [jupyter.org](https://jupyter.org/) y revisa el Makefile.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Internal Assets\n",
    "\n",
    "You can ignore this part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from collections import defaultdict\n",
    "\n",
    "# Loading libraries\n",
    "import pandas as pd\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration - Configuracion\n",
    "\n",
    "If you want to change settings, like data sources.\n",
    "\n",
    "---\n",
    "\n",
    "Si necesitas cambiar configuracion, como los acentos o la fuente de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distinguish accent (True = i and í are 2 different letters; False = they are 2 letter i's)\n",
    "accent_dif = False # False to ignore, as we won't be using them either for the exercises.\n",
    "\n",
    "# Data sources\n",
    "wordlist_fileSHORT = r'../data/Anexo I - palabras 3-9 letras.xls'\n",
    "wordlist_fileLONG = r'../data/Anexo II - palabras 10-16 letras.OLD.xls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics - Estidisticas\n",
    "\n",
    "Restart the counters\n",
    "\n",
    "---\n",
    "\n",
    "Reinicia los contadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clear Up the statistics\n",
    "\n",
    "## GLOBAL Variables\n",
    "# total of words counted\n",
    "word_sum = 0\n",
    "# Freq of each letter\n",
    "letter_frequency = defaultdict(lambda:0)\n",
    "# Percentile of each letter's frequency\n",
    "letter_freq_percent = defaultdict(lambda:0)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain list of usable words from 5 to 6 letters\n",
    "\n",
    "Using pandas and matplotlib.\n",
    "\n",
    "--- \n",
    "\n",
    "Utilizando pandas y matplotlib.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Obtain the list of words from the original database\n",
    "## SLOW Run carefully.\n",
    "\n",
    "#load the sheets for 5 and 6 letters words as Pandas DataFrames\n",
    "words5letters = pd.read_excel (wordlist_fileSHORT, sheet_name=\"5\")\n",
    "words6letters = pd.read_excel (wordlist_fileSHORT, sheet_name=\"6\")\n",
    "\n",
    "# Extract only the words and the lexyc frequency of words\n",
    "w5l = pd.DataFrame(words5letters ,columns=[\"PALABRA\",\"FRECUENC\"])\n",
    "w6l = pd.DataFrame(words6letters , columns=[\"PALABRA\", \"FRECUENC\"])\n",
    "w6l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the letters into the frequency database \n",
    "\n",
    "To build the statistics about how frequent each letter is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Obtain the full database\n",
    "## SLOW Run carefully.\n",
    "\n",
    "\n",
    "#load the sheets for 5 and 6 letters words as Pandas DataFrames\n",
    "all_words = pd.DataFrame(columns=[\"PALABRA\",\"FRECUENC\"])\n",
    "\n",
    "\n",
    "for i in range(3,10): # range from 3 to 9, inclusive\n",
    "    # wordlist_fileSHORT\n",
    "    sheety = pd.read_excel (wordlist_fileSHORT, sheet_name=f\"{i}\")\n",
    "    all_words = all_words.append( pd.DataFrame(sheety ,columns=[\"PALABRA\",\"FRECUENC\"]) )\n",
    "for i in range(10,17): # range from 10 to 16, inclusive\n",
    "    # wordlist_fileLONG\n",
    "    sheety = pd.read_excel (wordlist_fileLONG, sheet_name=f\"{i}\")\n",
    "    all_words = all_words.append(pd.DataFrame(sheety ,columns=[\"PALABRA\",\"FRECUENC\"]) )\n",
    "\n",
    "\n",
    "all_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the word into the stats D\n",
    "\n",
    "def is_vowel(letter):\n",
    "    \"\"\" returt if it's a vowel \"\"\"\n",
    "    return unidecode.unidecode(letter) in \"aeiou\"\n",
    "\n",
    "def no_accent(letter):\n",
    "    \"\"\" turn a letter into the no accent equivalent\"\"\"\n",
    "    return unidecode.unidecode(letter) \n",
    "\n",
    "assert is_vowel(\"a\") == True\n",
    "assert is_vowel(\"á\") == True\n",
    "assert is_vowel(\"v\") == False\n",
    "\n",
    "\n",
    "assert no_accent(\"a\") == \"a\"\n",
    "assert no_accent(\"á\") == \"a\"\n",
    "assert no_accent(\"v\") == \"v\"\n",
    "    \n",
    "def count_word(word, letter_frequency = letter_frequency, accent_dif = accent_dif):\n",
    "    \"\"\"\n",
    "    Given a word, update the global stats dictionary.\n",
    "    It considers if you want to distinguish accents or not.\n",
    "    \"\"\"\n",
    "    global word_sum\n",
    "    # don't count not numbers\n",
    "    if type(word) == type(0.1):\n",
    "        return None\n",
    "    # Count the word to the total of words\n",
    "    word_sum += 1\n",
    "    # We might need to exclude accents, but not the ñ\n",
    "    for letter in word:\n",
    "        if not accent_dif: # we must NOT distinguish accents\n",
    "            if is_vowel(letter):\n",
    "                letter_frequency[no_accent(letter)] += 1\n",
    "            else:\n",
    "                letter_frequency[letter] += 1\n",
    "        else:\n",
    "            letter_frequency[letter] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEBUG Error checking which words are missing on the new data set.\n",
    "\n",
    "filename = \"../data/ListaTodasPalabras.csv\"\n",
    "# Initialise some variables\n",
    "d = defaultdict(lambda:0)\n",
    "total = 0\n",
    "palabras = []\n",
    "\n",
    "with open(filename) as fh:\n",
    "    # count the total words and the letters\n",
    "    for word in fh.readlines():\n",
    "        if word == \"PALABRAS\\n\":\n",
    "            continue # Ignore the header name\n",
    "        total += 1\n",
    "        palabras.append(word.strip())\n",
    "        noacc = unidecode.unidecode(word)\n",
    "        for letter in noacc.strip():\n",
    "            d[letter] += 1\n",
    "\n",
    "\n",
    "print(\"Letter frequency from least to most\")\n",
    "s = {k: v for k, v in sorted(d.items(), key=lambda item: item[1])}\n",
    "\n",
    "\n",
    "for item,val in s.items():\n",
    "    print(f\"{item} : {val}\")\n",
    "\n",
    "\n",
    "def is_not_in(word, palabras=palabras):\n",
    "    if word in palabras:\n",
    "        return None\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "    \n",
    "assert is_not_in(\"aba\") == None\n",
    "assert is_not_in(\"somethingrandom\") == \"somethingrandom\"\n",
    "\n",
    "################ Contando palabras de un CSV pegado a mano\n",
    "\n",
    "print(\"Total words counted from CSV\")\n",
    "print(total)\n",
    "\n",
    "# TODO: There are some issues with importing the excel into pandas. some are fake nan.\n",
    "len(all_words) - len(palabras) # Equals 0. There are the same number of records, but some are \"nan\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG : Running it in one word (WARNING: State change)\n",
    "\n",
    "p = all_words[3].PALABRA[15]\n",
    "f = all_words[3].FRECUENC[15]\n",
    "\n",
    "print(p)\n",
    "print(f)\n",
    "\n",
    "print(\"Stadisticas antes\", word_sum )\n",
    "print(\"Stadisticas antes\", letter_frequency )\n",
    "count_word(p)\n",
    "print(\"Stadisticas despues\", word_sum )\n",
    "print(\"Stadisticas despues\", letter_frequency )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running it on all the words\n",
    "## Building the Freq Table. Run Once.\n",
    "\n",
    "palabras_not_in = []\n",
    "\n",
    "def build_letter_freq_table():\n",
    "    \"\"\"\n",
    "    Build the table with the total stats of letter frequency\n",
    "    \"\"\"\n",
    "    for idx, word in enumerate(all_words.PALABRA):\n",
    "        # make each letter into the stats dir.\n",
    "        try:\n",
    "            count_word(word)\n",
    "            if is_not_in(word):\n",
    "                palabras_not_in.append(word)\n",
    "        except TypeError as e:\n",
    "            print(e)\n",
    "            print(word)\n",
    "            print(type(word))\n",
    "            print(\"WTF\")\n",
    "    return None\n",
    "\n",
    "build_letter_freq_table()\n",
    "letter_frequency\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DEBUG: boilerplate to Running it on all the words\n",
    "\n",
    "palabras_not_in = []\n",
    "\n",
    "def loop_runner():\n",
    "    \"\"\"\n",
    "    Build the table with the total stats of letter frequency\n",
    "    \"\"\"\n",
    "    for idx, word in all_words.PALABRA.iteritems():\n",
    "        # make each letter into the stats dir.\n",
    "        try:\n",
    "            if is_not_in(word):\n",
    "                #palabras_not_in.append(word)\n",
    "                try:\n",
    "                    print(\"after\",all_words.PALABRA.get(idx-1))\n",
    "                    print(\"before\",all_words.PALABRA.get(idx+1))\n",
    "                except:\n",
    "                    pass\n",
    "        except TypeError as e:\n",
    "            print(e)\n",
    "            print(word)\n",
    "            print(type(word))\n",
    "            print(\"WTF\")\n",
    "    return None\n",
    "\n",
    "loop_runner()\n",
    "letter_frequency\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todelete: Another way to run stuff on all the words.\n",
    "# Trying to get missing words.\n",
    "\n",
    "for idx, word in all_words.PALABRA.iteritems():\n",
    "    if word == \"abejorreo\":\n",
    "        print(\"YAY\")\n",
    "    try:\n",
    "        #print(\"after\",all_words.PALABRA.get(idx-1))\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "\n",
    "#\"anatomopatólogo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMP Notes. How to merge 2 dataframes\n",
    "df1 = palabras # tendria que ser un data frame.\n",
    "df2 = all_words # all the words\n",
    "merged = df1.merge(df2, indicator=True, how='outer')\n",
    "merged[merged['_merge'] == 'right_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN: Check stats\n",
    "print(\"letter_frequency\",letter_frequency)\n",
    "print(\"word_sum\",word_sum)\n",
    "print(\"missing words\", len(palabras_not_in))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tenemos la tabla de frec. Necesitamos phi. Hay que calcular, el phi de una palabla.\n",
    "# para el phi, necesitamos, el % de frequencias\n",
    "\n",
    "#suma todas las frec de todas las letras\n",
    "tot_letters = 0 # all the counted letters\n",
    "for k,v in letter_frequency.items():\n",
    "    tot_letters += v\n",
    "    \n",
    "print(tot_letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of each letter's frequency\n",
    "\n",
    "# letter_freq_percent = defaultdict(lambda:0) #reset it for testing\n",
    "for letter,freq in letter_frequency.items():\n",
    "    letter_freq_percent[letter] = (letter_frequency[letter] * 100 ) / tot_letters\n",
    "    \n",
    "print(letter_freq_percent)\n",
    "\n",
    "# Validate that the percentile is correct\n",
    "check = 0\n",
    "for l,f in letter_freq_percent.items():\n",
    "    check+=f\n",
    "assert check == 100.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_phi(word):\n",
    "    \"\"\" Calculate Phi\n",
    "    Sum the frequency of each letter of the word\"\"\"\n",
    "    phi = 0\n",
    "    for letter in word:\n",
    "        phi += letter_freq_percent[letter]\n",
    "    return phi\n",
    "\n",
    "assert round(calculate_phi(\"aa\"),4) == round(31.511069684740857,4)\n",
    "assert calculate_phi(\"\") == 0 \n",
    "print( round(calculate_phi(\"busto\"),4), round(23.90546695497452,4 ))\n",
    "print( round(calculate_phi(\"casa\"),4), round(23.90546695497452,4 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# splitting the words into lists of letters\n",
    "splits = df.apply(lambda x: [y for y in x[0].strip()], axis='columns')\n",
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TXT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP Do not read forward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats of strokes per letter.\n",
    "rasgos = {\n",
    "        \"a\": 3,\n",
    "        \"b\": 4,\n",
    "        \"c\": 2,\n",
    "        \"d\": 3,\n",
    "        \"e\": 3,\n",
    "        \"f\": 4,\n",
    "        \"g\": 4,\n",
    "        \"h\": 4,\n",
    "        \"i\": 3,\n",
    "        \"j\": 3,\n",
    "        \"k\": 5,\n",
    "        \"l\": 2,\n",
    "        \"m\": 6,\n",
    "        \"n\": 4,\n",
    "        \"o\": 3,\n",
    "        \"p\": 4,\n",
    "        \"q\": 3,\n",
    "        \"r\": 3,\n",
    "        \"s\": 3,\n",
    "        \"t\": 4,\n",
    "        \"u\": 4,\n",
    "        \"v\": 4,\n",
    "        \"w\": 6,\n",
    "        \"x\": 4,\n",
    "        \"y\": 5,\n",
    "        \"z\": 5\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying to calculate Phi\n",
    "## Sum of all the % Frequency of each letter in the word\n",
    "\n",
    "def get_phi(letter):\n",
    "    return 1\n",
    "\n",
    "def calc_phi(word=None):\n",
    "    \"\"\" Calculate the phi value of a word.\n",
    "    Phi is the sum of the frequencies of the each letter in a word.\n",
    "    \"\"\"\n",
    "    if word is None:\n",
    "        return 0\n",
    "    phi = 0\n",
    "    for letter in word:\n",
    "        phi += get_phi(letter)\n",
    "    return phi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_phi(\"aa\"), 199)\n",
    "print(calc_phi(\"\"),0)\n",
    "print(calc_phi(),0)\n",
    "print(calc_phi(\"abadia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying to calculate Stroke sum RHO\n",
    "## Sum of all the strokes of each letter in a word\n",
    "\n",
    "def get_rho(letter):\n",
    "    return rasgos[letter]\n",
    "\n",
    "def calc_rho(word=None):\n",
    "    \"\"\" Calculate the Rho value of a word.\n",
    "    Rho is the sum of the strokes of the each letter in a word.\n",
    "    \"\"\"\n",
    "    if word is None:\n",
    "        return 0\n",
    "    rho = 0\n",
    "    for letter in word:\n",
    "        rho += get_rho(letter)\n",
    "    return rho\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_rho(\"aa\"), 6)\n",
    "print(calc_rho(\"\"),0)\n",
    "print(calc_rho(),0)\n",
    "print(calc_rho(\"peluca\"),18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
